# syntax=docker/dockerfile:1.6

ARG CUDA_VERSION=12.8.0
ARG PYTHON_VERSION=3.11
ARG PYTORCH_INDEX=https://download.pytorch.org/whl/cu128

############################
# Build stage: compile vLLM
############################
FROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu22.04 AS build
ARG PYTHON_VERSION
ARG PYTORCH_INDEX
ENV DEBIAN_FRONTEND=noninteractive
WORKDIR /workspace/vllm

RUN apt-get update \
    && apt-get install -y --no-install-recommends \
        python${PYTHON_VERSION} \
        python${PYTHON_VERSION}-dev \
        python3-pip \
        python-is-python3 \
        git \
        build-essential \
        ninja-build \
        cmake \
        curl \
    && rm -rf /var/lib/apt/lists/*

RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 1 \
    && python3 -m pip install --upgrade pip setuptools wheel

COPY requirements requirements

RUN pip install --no-cache-dir --extra-index-url ${PYTORCH_INDEX} -r requirements/cuda.txt \
    && pip install --no-cache-dir --extra-index-url ${PYTORCH_INDEX} -r requirements/build.txt

COPY . .

# Cover common NVIDIA architectures for CUDA kernels
ENV TORCH_CUDA_ARCH_LIST="7.0 7.5 8.0 8.9 9.0 10.0 12.0"

RUN python3 setup.py bdist_wheel --dist-dir /tmp/dist

############################
# Runtime stage: install vLLM
############################
FROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu22.04
ARG PYTHON_VERSION
ARG PYTORCH_INDEX
ENV DEBIAN_FRONTEND=noninteractive
WORKDIR /opt/vllm

RUN apt-get update \
    && apt-get install -y --no-install-recommends \
        python${PYTHON_VERSION} \
        python${PYTHON_VERSION}-venv \
        python3-pip \
        python-is-python3 \
        libnuma1 \
    && rm -rf /var/lib/apt/lists/*

RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 1 \
    && python3 -m pip install --upgrade pip

COPY --from=build /tmp/dist /tmp/dist
COPY requirements requirements
COPY . .

RUN pip install --no-cache-dir /tmp/dist/*.whl \
    && pip install --no-cache-dir --extra-index-url ${PYTORCH_INDEX} -r requirements/cuda.txt

ENV VLLM_TARGET_DEVICE=cuda
EXPOSE 8000
ENTRYPOINT ["vllm", "serve"]
